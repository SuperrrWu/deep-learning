让神经网络学习更快
二次代价函数：（1/2n）*Σxabs(y(x)-a)^2
分别对w和b求偏导数：
sigmoid函数：
当神经元接近1时，曲线很平缓，所以求微分很小，学习率较低。
C=-(1/n)Σ[ylna+(1-y)ln(1-a)]
cross-entrpy cost几乎总是比二次cost函数好
如果神经元函数是二次型，可以使用二次cost函数

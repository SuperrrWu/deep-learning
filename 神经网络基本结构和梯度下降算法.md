神经网络基本结构和梯度下降算法

![神经网络原理图](https://github.com/SuperrrWu/deep-learning/blob/master/Image/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%95%E7%A4%BA%E5%9B%BE.jpg)
deep-learning的深度是指hidden layers
x:训练输入
y:训练输出
Cost-function（目标函数、损失函数）:
C(w,b)=Σx(1/2n)*abs(y(x)-t)
最小化问题可以使用梯度下降解决（gradient descent）
C(w,b)有两个变量，我们定义为V1，V2。
这是一个三维图像
